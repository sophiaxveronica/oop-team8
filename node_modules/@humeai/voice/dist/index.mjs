// src/lib/audio.ts
var MimeType = /* @__PURE__ */ ((MimeType2) => {
  MimeType2["WEBM"] = "audio/webm";
  MimeType2["MP4"] = "audio/mp4";
  MimeType2["WAV"] = "audio/wav";
  return MimeType2;
})(MimeType || {});
function arrayBufferToBlob(arrayBuffer, mimeType) {
  return new Blob([arrayBuffer], { type: mimeType });
}
function base64ToBlob(base64, contentType) {
  const binaryString = window.atob(base64);
  const bytes = new Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  const byteArray = new Uint8Array(bytes);
  return new Blob([byteArray], { type: contentType });
}
function getSupportedMimeType() {
  if (typeof MediaRecorder === "undefined") {
    return {
      success: false,
      error: new Error("MediaRecorder is not supported")
    };
  }
  if (MediaRecorder.isTypeSupported("audio/webm" /* WEBM */)) {
    return { success: true, mimeType: "audio/webm" /* WEBM */ };
  }
  if (MediaRecorder.isTypeSupported("audio/mp4" /* MP4 */)) {
    return { success: true, mimeType: "audio/mp4" /* MP4 */ };
  }
  if (MediaRecorder.isTypeSupported("audio/wav" /* WAV */)) {
    return { success: true, mimeType: "audio/wav" /* WAV */ };
  }
  return {
    success: false,
    error: new Error("Browser does not support any compatible mime types")
  };
}

// src/lib/client.ts
import ReconnectingWebsocket from "reconnecting-websocket";
import snakecaseKeys from "snakecase-keys";

// src/lib/create-url.ts
var createSocketUrl = (config) => {
  const url = new URL(`wss://${config.hostname}`);
  url.pathname = "/v0/evi/chat";
  if (config.auth.type === "accessToken") {
    url.searchParams.set("accessToken", config.auth.value);
  } else if (config.auth.type === "apiKey") {
    url.searchParams.set("apiKey", config.auth.value);
  }
  if (config.configId) {
    url.searchParams.set("config_id", config.configId);
  }
  if (config.configVersion) {
    url.searchParams.set("config_version", String(config.configVersion));
  }
  if (config.resumedChatGroupId) {
    url.searchParams.set(
      "resumed_chat_group_id",
      String(config.resumedChatGroupId)
    );
  }
  return url.href;
};

// src/lib/errors.ts
var SocketUnknownMessageError = class extends Error {
  constructor(message) {
    super(`Unknown message type.${message ? " " + message : ""}`);
    this.name = "SocketUnknownMessageError";
  }
};
var isSocketUnknownMessageError = (err) => {
  return err instanceof SocketUnknownMessageError;
};
var SocketFailedToParseMessageError = class extends Error {
  constructor(message) {
    super(
      `Failed to parse message from socket.${message ? " " + message : ""}`
    );
    this.name = "SocketFailedToParseMessageError";
  }
};
var isSocketFailedToParseMessageError = (err) => {
  return err instanceof SocketFailedToParseMessageError;
};

// src/models/audio-message.ts
import z from "zod";
var AudioMessageSchema = z.object({
  type: z.literal("audio"),
  data: z.instanceof(ArrayBuffer)
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});
var parseAudioMessage = async (blob) => {
  return blob.arrayBuffer().then((buffer) => {
    return {
      type: "audio",
      data: buffer,
      receivedAt: /* @__PURE__ */ new Date()
    };
  }).catch(() => {
    return null;
  });
};

// src/models/json-message.ts
import z12 from "zod";

// src/models/assistant-end-message.ts
import z2 from "zod";
var AssistantEndMessageSchema = z2.object({
  type: z2.literal("assistant_end")
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/assistant-message.ts
import z4 from "zod";

// src/models/transcript-models.ts
import z3 from "zod";
var EmotionScoresSchema = z3.record(z3.string(), z3.number());
var TranscriptModelsSchema = z3.object({
  // prosody scores are null when the message is not audio
  // (e.g. text input from the user)
  prosody: z3.object({
    scores: EmotionScoresSchema
  }).nullish(),
  time: z3.object({
    begin: z3.number(),
    end: z3.number()
  }).nullish()
});

// src/models/assistant-message.ts
var AssistantTranscriptMessageSchema = z4.object({
  type: z4.literal("assistant_message"),
  id: z4.string(),
  message: z4.object({
    role: z4.literal("assistant"),
    content: z4.string()
  }),
  models: TranscriptModelsSchema,
  from_text: z4.boolean().catch(false)
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/audio-output-message.ts
import { z as z5 } from "zod";
var AudioOutputMessageSchema = z5.object({
  type: z5.literal("audio_output"),
  id: z5.string(),
  data: z5.string()
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/chat-metadata-message.ts
import z6 from "zod";
var ChatMetadataMessageSchema = z6.object({
  type: z6.literal("chat_metadata"),
  chat_id: z6.string(),
  chat_group_id: z6.string()
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/error-message.ts
import { z as z7 } from "zod";
var JSONErrorMessageSchema = z7.object({
  type: z7.literal("error"),
  code: z7.string(),
  slug: z7.string(),
  message: z7.string()
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/tool-messages.ts
import z8 from "zod";
var literalSchema = z8.union([z8.string(), z8.number(), z8.boolean(), z8.null()]);
var jsonSchema = z8.lazy(
  () => z8.union([literalSchema, z8.array(jsonSchema), z8.record(jsonSchema)])
);
var ToolCallSchema = z8.object({
  type: z8.literal("tool_call"),
  tool_type: z8.enum(["builtin", "function"]),
  tool_call_id: z8.string(),
  response_required: z8.boolean(),
  name: z8.string(),
  parameters: z8.string()
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});
var ToolResponseContentSchema = z8.union([z8.string(), jsonSchema]);
var ToolResponseSchema = z8.object({
  type: z8.literal("tool_response"),
  tool_call_id: z8.string(),
  content: ToolResponseContentSchema,
  tool_name: z8.string().optional(),
  tool_type: z8.enum(["builtin", "function"]).optional()
});
var ToolErrorSchema = z8.object({
  type: z8.literal("tool_error"),
  tool_call_id: z8.string(),
  content: z8.string().nullish(),
  error: z8.string(),
  code: z8.string(),
  level: z8.string()
});

// src/models/user-interruption-message.ts
import z10 from "zod";

// src/models/time-slice.ts
import { z as z9 } from "zod";
var TimeSliceSchema = z9.object({
  begin: z9.number(),
  end: z9.number()
});

// src/models/user-interruption-message.ts
var UserInterruptionMessageSchema = z10.object({
  type: z10.literal("user_interruption"),
  time: z10.union([TimeSliceSchema, z10.number(), z10.null()]).catch(null)
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/user-message.ts
import z11 from "zod";
var UserTranscriptMessageSchema = z11.object({
  type: z11.literal("user_message"),
  message: z11.object({
    role: z11.literal("user"),
    content: z11.string()
  }),
  models: TranscriptModelsSchema,
  from_text: z11.boolean().nullish().catch(false)
}).transform((obj) => {
  return Object.assign(obj, {
    receivedAt: /* @__PURE__ */ new Date()
  });
});

// src/models/json-message.ts
var JSONMessageSchema = z12.union([
  AudioOutputMessageSchema,
  AssistantEndMessageSchema,
  UserInterruptionMessageSchema,
  UserTranscriptMessageSchema,
  AssistantTranscriptMessageSchema,
  JSONErrorMessageSchema,
  ToolCallSchema,
  ToolErrorSchema,
  ToolResponseSchema,
  ChatMetadataMessageSchema
]);

// src/utils/safeJson.ts
var safeJson = (input) => {
  try {
    return { success: true, data: JSON.parse(input) };
  } catch (e) {
    return { success: false };
  }
};

// src/utils/unwrapJson.ts
var unwrapJson = (input, schema) => {
  const json = safeJson(input);
  if (!json.success) {
    return null;
  }
  const message = schema.safeParse(json.data);
  if (!message.success) {
    return null;
  }
  return message.data;
};

// src/lib/message.ts
var parseMessageData = async (data) => {
  if (data instanceof Blob) {
    const message = await parseAudioMessage(data);
    if (message) {
      return {
        success: true,
        message
      };
    } else {
      return {
        success: false,
        error: new SocketFailedToParseMessageError(
          `Received blob was unable to be converted to ArrayBuffer.`
        )
      };
    }
  }
  if (typeof data !== "string") {
    return {
      success: false,
      error: new SocketFailedToParseMessageError(
        `Expected a string but received ${typeof data}.`
      )
    };
  }
  const obj = unwrapJson(data, JSONMessageSchema);
  if (obj === null) {
    return {
      success: false,
      error: new SocketUnknownMessageError(
        `Received JSON was not a known message type.`
      )
    };
  }
  return {
    success: true,
    message: obj
  };
};
var parseMessageType = async (event) => {
  const data = event.data;
  return parseMessageData(data);
};

// src/lib/client.ts
var VoiceClient = class _VoiceClient {
  socket;
  url;
  eventHandlers = {};
  constructor(config) {
    this.url = createSocketUrl(config);
    this.socket = new ReconnectingWebsocket(this.url, [], {
      startClosed: true,
      maxRetries: config.reconnectAttempts,
      debug: config.debug
    });
  }
  /**
   * @name create
   * @description
   * Create a new VoiceClient.
   * @param config - The configuration for the client.
   * @returns
   * A new VoiceClient instance.
   * @example
   * ```ts
   * const client = VoiceClient.create(config);
   * ```
   */
  static create(config) {
    return new _VoiceClient(config);
  }
  /**
   * @name on
   * @description
   * Attach events to the client.
   * @param event - The event to attach to.
   * @param callback - The callback to run when the event is triggered.
   * @returns
   * The VoiceClient instance.
   * @example
   * ```ts
   * const client = VoiceClient.create(config);
   * client.on('open', () => {
   *  console.log('Socket opened');
   * });
   * ```
   */
  on(event, callback) {
    this.eventHandlers[event] = callback;
  }
  handleOpen = () => {
    this.eventHandlers.open?.();
  };
  handleMessage = (event) => {
    void parseMessageType(event).then((result) => {
      if (result.success) {
        this.eventHandlers.message?.(result.message);
      }
    });
  };
  handleClose = (event) => {
    this.eventHandlers.close?.(event);
  };
  handleError = (e) => {
    const message = e.message ?? "WebSocket error";
    this.eventHandlers.error?.(new Error(message));
  };
  /**
   * @name connect
   * @description
   * Connect to the websocket.
   */
  connect() {
    this.socket.reconnect();
    this.socket.addEventListener("open", this.handleOpen);
    this.socket.addEventListener("message", this.handleMessage);
    this.socket.addEventListener("close", this.handleClose);
    this.socket.addEventListener("error", this.handleError);
    return this;
  }
  /**
   * @name disconnect
   * @description
   * Disconnect from the websocket.
   */
  disconnect() {
    this.socket?.close();
    this.handleClose({ code: 1e3 });
    this.socket.removeEventListener("open", this.handleOpen);
    this.socket.removeEventListener("message", this.handleMessage);
    this.socket.removeEventListener("close", this.handleClose);
    this.socket.removeEventListener("error", this.handleError);
  }
  /**
   * @name sendAudio
   * @description
   * Send audio data to the websocket.
   */
  sendAudio(audioBuffer) {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    this.socket.send(audioBuffer);
  }
  /**
   * @name sendUserInput
   * @description
   * Send text data to the websocket.
   */
  sendUserInput(text) {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const json = JSON.stringify({ text, type: "user_input" });
    this.socket.send(json);
  }
  /**
   * @name sendAssistantInput
   * @description
   * Send text data to the websocket for TTS.
   */
  sendAssistantInput(text) {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const json = JSON.stringify({ text, type: "assistant_input" });
    this.socket.send(json);
  }
  /**
   * @name sendSessionSettings
   * @description
   * Send session settings to the websocket
   */
  sendSessionSettings(sessionSettings) {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const snakeCaseSettings = snakecaseKeys(sessionSettings);
    const json = JSON.stringify({
      ...snakeCaseSettings,
      type: "session_settings"
    });
    this.socket.send(json);
  }
  /**
   * @name sendToolMessage
   * @description
   * Send tool response to the websocket, e.g. for function calling
   */
  sendToolMessage(toolMessage) {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const json = JSON.stringify(toolMessage);
    this.socket.send(json);
  }
  /**
   * @name readyState
   * @description
   * The current ready state of the socket.
   */
  get readyState() {
    return this.socket.readyState;
  }
  /**
   * @name sendPauseAssistantMessage
   * @description
   * Send pause assistant message to the websocket. This pauses responses from EVI. Chat history is still saved and sent after resuming.
   */
  sendPauseAssistantMessage() {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const json = JSON.stringify({ type: "pause_assistant_message" });
    this.socket.send(json);
  }
  /**
   * @name sendResumeAssistantMessage
   * @description
   * Send resume assistant message to the websocket. This resumes responses from EVI. Chat history sent while paused will now be sent.
   */
  sendResumeAssistantMessage() {
    if (!this.socket) {
      throw new Error("Socket is not connected.");
    }
    if (this.socket.readyState !== WebSocket.OPEN) {
      throw new Error("Socket is not open.");
    }
    const json = JSON.stringify({ type: "resume_assistant_message" });
    this.socket.send(json);
  }
};

// src/lib/create-socket-config.ts
import { z as z14 } from "zod";

// src/models/auth.ts
import z13 from "zod";
var AuthStrategySchema = z13.union([
  z13.object({
    type: z13.literal("apiKey"),
    value: z13.string({
      description: "API key for the Hume API is required"
    })
  }),
  z13.object({
    type: z13.literal("accessToken"),
    value: z13.string({
      description: "Access token for the Hume API is required"
    })
  })
]);

// src/lib/create-socket-config.ts
var SocketConfigSchema = z14.object({
  // Configs that are set at connection time
  hostname: z14.string({
    description: "Hostname of the Hume API."
  }),
  reconnectAttempts: z14.number({
    description: "Number of times to attempt to reconnect to the API."
  }).optional().default(30),
  debug: z14.boolean({
    description: "Enable debug mode."
  }).optional().default(false),
  // Configs that are set as query params
  auth: AuthStrategySchema,
  configId: z14.string({
    description: "The ID of the configuration to use."
  }).optional(),
  configVersion: z14.number({
    description: "The version of the configuration to use."
  }).optional(),
  resumedChatGroupId: z14.string({
    description: "The ID of the chat group to resume."
  }).optional()
});
var defaultConfig = {
  hostname: "api.hume.ai",
  reconnectAttempts: 30,
  debug: false
};
var createSocketConfig = (config) => {
  if (!config.auth)
    throw new Error("Auth strategy is required.");
  return SocketConfigSchema.parse({
    ...defaultConfig,
    ...config,
    auth: config.auth
  });
};

// src/lib/tts.ts
var TTSService = /* @__PURE__ */ ((TTSService2) => {
  TTSService2["DEFAULT"] = "hume_ai";
  TTSService2["ELEVEN_LABS"] = "eleven_labs";
  TTSService2["PLAY_HT"] = "play_ht";
  return TTSService2;
})(TTSService || {});

// src/lib/microphone.ts
var getAudioStream = async () => {
  return navigator.mediaDevices.getUserMedia({
    audio: {
      echoCancellation: true,
      noiseSuppression: true,
      autoGainControl: true
    },
    video: false
  });
};
var checkForAudioTracks = (stream) => {
  const tracks = stream.getAudioTracks();
  if (tracks.length === 0) {
    throw new Error("No audio tracks");
  }
  if (tracks.length > 1) {
    throw new Error("Multiple audio tracks");
  }
  const track = tracks[0];
  if (!track) {
    throw new Error("No audio track");
  }
};

// src/lib/fetch-access-token.ts
function base64Encode(str) {
  if (typeof Buffer === "function") {
    return Buffer.from(str).toString("base64");
  } else if (typeof btoa === "function") {
    return btoa(str);
  } else {
    throw new Error(
      "Base64 encoding is not natively supported in this environment."
    );
  }
}
var fetchAccessToken = async (args) => {
  const { apiKey, secretKey, host = "api.hume.ai" } = args;
  const authString = `${apiKey}:${secretKey}`;
  const encoded = base64Encode(authString);
  const res = await fetch(`https://${host}/oauth2-cc/token`, {
    method: "POST",
    headers: {
      "Content-Type": "application/x-www-form-urlencoded",
      Authorization: `Basic ${encoded}`
    },
    body: new URLSearchParams({
      grant_type: "client_credentials"
    }).toString(),
    cache: "no-cache"
  });
  const data = await res.json();
  const accessToken = String(data["access_token"]);
  return accessToken;
};

// src/models/session-settings.ts
import z15 from "zod";
var Channels = /* @__PURE__ */ ((Channels2) => {
  Channels2[Channels2["MONO"] = 1] = "MONO";
  Channels2[Channels2["STEREO"] = 2] = "STEREO";
  return Channels2;
})(Channels || {});
var AudioEncoding = /* @__PURE__ */ ((AudioEncoding2) => {
  AudioEncoding2["LINEAR16"] = "linear16";
  AudioEncoding2["OPUS"] = "opus";
  return AudioEncoding2;
})(AudioEncoding || {});
var AudioConfigurationSchema = z15.object({
  channels: z15.nativeEnum(Channels, {
    description: "Number of channels in the input audio."
  }),
  encoding: z15.nativeEnum(AudioEncoding, {
    description: "Encoding of the input audio."
  }),
  sampleRate: z15.number({
    description: "Sample rate of the input audio."
  })
});
var ContextConfigurationSchema = z15.object({
  text: z15.string(),
  type: z15.enum(["editable", "persistent", "temporary"]).optional()
});
var WebSearchToolSchema = z15.object({
  name: z15.literal("web_search"),
  fallback_content: z15.string().nullish().catch(null)
});
var SessionSettingsSchema = z15.object({
  audio: AudioConfigurationSchema.optional(),
  context: ContextConfigurationSchema.optional(),
  languageModelApiKey: z15.string().optional(),
  customSessionId: z15.string().optional(),
  systemPrompt: z15.string().optional(),
  builtin_tools: z15.array(z15.union([WebSearchToolSchema, z15.null()])).optional()
});

// src/models/llm.ts
var LanguageModelOption = /* @__PURE__ */ ((LanguageModelOption2) => {
  LanguageModelOption2["CLAUDE_3_OPUS"] = "CLAUDE_3_OPUS";
  LanguageModelOption2["CLAUDE_3_SONNET"] = "CLAUDE_3_SONNET";
  LanguageModelOption2["CLAUDE_3_HAIKU"] = "CLAUDE_3_HAIKU";
  LanguageModelOption2["CLAUDE_21"] = "CLAUDE_21";
  LanguageModelOption2["CLAUDE_INSTANT_12"] = "CLAUDE_INSTANT_12";
  LanguageModelOption2["GPT_4_TURBO_PREVIEW"] = "GPT_4_TURBO_PREVIEW";
  LanguageModelOption2["GPT_35_TURBO_0125"] = "GPT_35_TURBO_0125";
  LanguageModelOption2["GPT_35_TURBO"] = "GPT_35_TURBO";
  LanguageModelOption2["FIREWORKS_MIXTRAL_8X7B"] = "FIREWORKS_MIXTRAL_8X7B";
  return LanguageModelOption2;
})(LanguageModelOption || {});
export {
  AssistantEndMessageSchema,
  AssistantTranscriptMessageSchema,
  AudioEncoding,
  AudioMessageSchema,
  AudioOutputMessageSchema,
  AuthStrategySchema,
  Channels,
  ChatMetadataMessageSchema,
  EmotionScoresSchema,
  JSONErrorMessageSchema,
  JSONMessageSchema,
  LanguageModelOption,
  MimeType,
  SessionSettingsSchema,
  SocketConfigSchema,
  SocketFailedToParseMessageError,
  SocketUnknownMessageError,
  TTSService,
  TimeSliceSchema,
  ToolCallSchema,
  ToolErrorSchema,
  ToolResponseContentSchema,
  ToolResponseSchema,
  TranscriptModelsSchema,
  UserInterruptionMessageSchema,
  UserTranscriptMessageSchema,
  VoiceClient,
  WebSearchToolSchema,
  arrayBufferToBlob,
  base64ToBlob,
  checkForAudioTracks,
  createSocketConfig,
  createSocketUrl,
  defaultConfig,
  fetchAccessToken,
  getAudioStream,
  getSupportedMimeType,
  isSocketFailedToParseMessageError,
  isSocketUnknownMessageError,
  parseAudioMessage,
  parseMessageData,
  parseMessageType
};
//# sourceMappingURL=index.mjs.map